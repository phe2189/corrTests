---
title: "Further Examples of corrTests Package"
author: "Philip He"
date: "10/2/2022"
output:
  pdf_document:
    toc: yes
    number_sections: yes
  html_document:
    toc: yes
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction
```{r}
library(corrTests)
```

R package `corrTests` provides the calculation of rejection boundaries and power for correlated logrank tests used in overlapping populations. Refer to the manuscript for technical details.

The core functions in `corrTests` include: (1) `corrBounds` - 	Rejection Boundaries Of Correlated Tests in Group Sequential Design Using Time-To-Event Endpoints (2) `corrPower` - Power Calculation for Log-rank Tests in Overlapping Populations, (3) `corrTime` - Correlation Between Two Logrank Test Statistics Over Time With Staggered Entry. One supportive function is also included `corrEvents` - Expected Number of Events Over Time With Staggered Entry For Overlapping Populations. 

Section 2 describes the installation instructions, and Section 3 - 5 describe each of the core functions and examples.

# Installation of `corrTests`

The R package is still under development and it is associated with the manuscript. For installation, please follow the following instructions to install it locally. It depends on `gsDesign`, `mvtnorm` and `devtools`. They need to be installed first.

```
#Install devtools if not installed
install.packages("devtools")

#Unzip the file and save to a local folder like C:/myfolder/corrTests

##Uninstall the previous version
remove.packages("corrTests")

#Install the package
devtools::install(pkg="C:/myfolder/corrTests") 

#Load the package
library(corrTests)

#Browse the functions in the package
help(package="corrTests")
```

# Function `corrBounds`

This function calculates the rejection boundaries in p value (significance level) and z value in group sequential design based on the alpha spending function for each test using the log-rank test. 

## Example 1. Single-time analysis

Consider two hypothesis tests for a subgroup and overall population have single time analysis. The number of target events is 100 for the subgroup and 150 for the overall population respectively. Assume the randomization is 1:1 and the family-wise 1-sided type I error 0.025 is allocated to the subgroup and overall population with weights 1/3 and 2/3 respectively.

### Balanced allocation of efficiency; stratified analysis

```{r}
corrBounds(sf=list(sfuA=gsDesign::sfLDOF, sfuB=gsDesign::sfLDOF), 
   eAandB = c(100), eAnotB = c(0), eBnotA = c(50),
   r=list(AandB = 1/2, AnotB=0, BnotA=1/2), rA=1/2, rB=1/2, gamma = NA,
   strat.ana=c("Y", "N"),alpha=0.025, w=c(1/3, 2/3),epsA = c(NA,NA), epsB=c(1,1),
   method=c("Balanced Allocation", "Customized Allocation"))
```

### Balanced allocation of efficiency; unstratified analysis

For un-stratified analysis, the parameter `gamma` is required, which is the proportion of subjects in the overlapped subgroup among all subjects. For this example, `gamma` is the proportion of subjects in the subgroup. Assume the subgroup has prevalence of 70%, i.e., `gamma = 0.7` in this example. Then the rejection boundary can be calculated below.

```{r}
corrBounds(sf=list(sfuA=gsDesign::sfLDOF, sfuB=gsDesign::sfLDOF), 
   eAandB = c(100), eAnotB = c(0), eBnotA = c(50),
   r=list(AandB = 1/2, AnotB=0, BnotA=1/2), rA=1/2, rB=1/2, gamma = 0.7,
   strat.ana="N",alpha=0.025, w=c(1/3, 2/3),epsA = c(NA,NA), epsB=c(1,1),
   method=c("Balanced Allocation", "Customized Allocation"))
```

### Customized Allocation of efficiency: Only improve the overall population, stratified Analysis

```{r}
corrBounds(sf=list(sfuA=gsDesign::sfLDOF, sfuB=gsDesign::sfLDOF), 
   eAandB = c(100), eAnotB = c(0), eBnotA = c(50),
   r=list(AandB = 1/2, AnotB=0, BnotA=1/2), rA=1/2, rB=1/2, gamma = NA,
   strat.ana=c("Y"),alpha=0.025, w=c(1/3, 2/3),epsA = c(1), epsB=c(NA),
   method=c("Customized Allocation"))
```

### Customized Allocation of efficiency: Only improve the overall population, unstratified Analysis

```{r}
corrBounds(sf=list(sfuA=gsDesign::sfLDOF, sfuB=gsDesign::sfLDOF), 
   eAandB = c(100), eAnotB = c(0), eBnotA = c(50),
   r=list(AandB = 1/2, AnotB=0, BnotA=1/2), rA=1/2, rB=1/2, gamma = 0.8,
   strat.ana=c("N"),alpha=0.025, w=c(1/3, 2/3),epsA = c(1), epsB=c(NA),
   method=c("Customized Allocation"))
```

## Example 2. Group sequential design

Consider a group sequential design with the O'Brien Fleming spending function used for both tests Ha and Hb, and only one interim analysis. The number of events at IA and FA in each set of patients are: (126, 210), (0,0), (54,90) for in A and B, in A not B, in B not A respectively. So the events ratio at IA for testing Ha is 126/180 = 0.7; and for testing Hb is 210 / 300 = 0.70. The overall type I error is split as 1/3 alpha and 2/3 alpha.

### Balanced Allocation of Efficiency: Stratified Analysis

```{r}
corrBounds(sf=list(sfuA=gsDesign::sfLDOF, sfuB=gsDesign::sfLDOF), 
   eAandB = c(126, 210), eAnotB = c(0,0), eBnotA = c(54, 90),
   r=list(AandB = 1/2, AnotB=0, BnotA=1/2), rA=1/2, rB=1/2, gamma = NA,
   strat.ana="Y",alpha=0.025, w=c(1/3, 2/3),epsA = c(NA,NA), epsB=c(NA,NA),
   method="Balanced Allocation")
```

### Balanced Allocation of Efficiency: Unstratified Analysis


```{r}
corrBounds(sf=list(sfuA=gsDesign::sfLDOF, sfuB=gsDesign::sfLDOF), 
   eAandB = c(126, 210), eAnotB = c(0,0), eBnotA = c(54, 90),
   r=list(AandB = 1/2, AnotB=0, BnotA=1/2), rA=1/2, rB=1/2, gamma = 0.8,
   strat.ana="N",alpha=0.025, w=c(1/3, 2/3),epsA = c(NA,NA), epsB=c(NA,NA),
   method="Balanced Allocation")
```

### Improve Ha only, Stratified Analysis

```{r}
corrBounds(sf=list(sfuA=gsDesign::sfLDOF, sfuB=gsDesign::sfLDOF), 
   eAandB = c(126, 210), eAnotB = c(0,0), eBnotA = c(54, 90),
   r=list(AandB = 1/2, AnotB=0, BnotA=1/2), rA=1/2, rB=1/2, gamma = NA,
   strat.ana="Y",alpha=0.025, w=c(1/3, 2/3),epsA = c(NA,NA), epsB=c(1,1),
   method="Customized Allocation")
```


### Improve Ha only, Unstratified Analysis    


```{r}
corrBounds(sf=list(sfuA=gsDesign::sfLDOF, sfuB=gsDesign::sfLDOF), 
   eAandB = c(126, 210), eAnotB = c(0,0), eBnotA = c(54, 90),
   r=list(AandB = 1/2, AnotB=0, BnotA=1/2), rA=1/2, rB=1/2, gamma = 0.8,
   strat.ana="N",alpha=0.025, w=c(1/3, 2/3),epsA = c(NA,NA), epsB=c(1,1),
   method="Customized Allocation")
```


### Improve Hb only, Stratified Analysis


```{r}
corrBounds(sf=list(sfuA=gsDesign::sfLDOF, sfuB=gsDesign::sfLDOF), 
   eAandB = c(126, 210), eAnotB = c(0,0), eBnotA = c(54, 90),
   r=list(AandB = 1/2, AnotB=0, BnotA=1/2), rA=1/2, rB=1/2, gamma = NA,
   strat.ana="Y",alpha=0.025, w=c(1/3, 2/3),epsA = c(1,1), epsB=c(NA,NA),
   method="Customized Allocation")
```


### Improve Hb only, Unstratified Analysis    


```{r}
corrBounds(sf=list(sfuA=gsDesign::sfLDOF, sfuB=gsDesign::sfLDOF), 
   eAandB = c(126, 210), eAnotB = c(0,0), eBnotA = c(54, 90),
   r=list(AandB = 1/2, AnotB=0, BnotA=1/2), rA=1/2, rB=1/2, gamma = 0.8,
   strat.ana="N",alpha=0.025, w=c(1/3, 2/3),epsA = c(1,1), epsB=c(NA,NA),
   method="Customized Allocation")
```


### Improve Ha at IA and improve Hb at FA. Stratified Analysis


```{r}
corrBounds(sf=list(sfuA=gsDesign::sfLDOF, sfuB=gsDesign::sfLDOF), 
   eAandB = c(126, 210), eAnotB = c(0,0), eBnotA = c(54, 90),
   r=list(AandB = 1/2, AnotB=0, BnotA=1/2), rA=1/2, rB=1/2, gamma = NA,
   strat.ana="Y",alpha=0.025, w=c(1/3, 2/3),epsA = c(NA,1), epsB=c(1,NA),
   method="Customized Allocation")
```

### Improve Ha at IA and improve Hb at FA, Unstratified Analysis


```{r}
corrBounds(sf=list(sfuA=gsDesign::sfLDOF, sfuB=gsDesign::sfLDOF), 
   eAandB = c(126, 210), eAnotB = c(0,0), eBnotA = c(54, 90),
   r=list(AandB = 1/2, AnotB=0, BnotA=1/2), rA=1/2, rB=1/2, gamma = 0.8,
   strat.ana="N",alpha=0.025, w=c(1/3, 2/3),epsA = c(NA,1), epsB=c(1,NA),
   method="Customized Allocation")
```

### Improve Hb at IA and improve Ha at FA, Stratified Analysis


```{r}
corrBounds(sf=list(sfuA=gsDesign::sfLDOF, sfuB=gsDesign::sfLDOF), 
   eAandB = c(126, 210), eAnotB = c(0,0), eBnotA = c(54, 90),
   r=list(AandB = 1/2, AnotB=0, BnotA=1/2), rA=1/2, rB=1/2, gamma = NA,
   strat.ana="Y",alpha=0.025, w=c(1/3, 2/3),epsA = c(1,NA), epsB=c(NA,1),
   method="Customized Allocation")
```

### Improve Hb at IA and improve Ha at FA, Unstratified Analysis


```{r}
corrBounds(sf=list(sfuA=gsDesign::sfLDOF, sfuB=gsDesign::sfLDOF), 
   eAandB = c(126, 210), eAnotB = c(0,0), eBnotA = c(54, 90),
   r=list(AandB = 1/2, AnotB=0, BnotA=1/2), rA=1/2, rB=1/2, gamma = 0.8,
   strat.ana="N",alpha=0.025, w=c(1/3, 2/3),epsA = c(1,NA), epsB=c(NA,1),
   method="Customized Allocation")
```

## Example 3. JAVELIN-100 Study

JAVELIN-100 (Powles et al 2020) is a phase 3 study of maintenance therapy for advanced or metastatic urothelial carcinoma. The dual primary endpoints are OS in PD-L1+ population (H_A) and overall population (H_B). Subjects were equally randomized to receive best supportive care (BSC) with or without avelumab (N = 350 for each group). The randomization was stratified by best response to first line chemotherapy (CR or PR vs SD) and metastatic site (visceral vs non-visceral) at the time of initiating first-line chemotherapy, but not by PD-L1 status. Among subjects with evaluable tissue samples, 189 patients in the avelumab group and in 169 in the control group are PD-L1 positive. The primary analysis of the overall population is not stratified by PD-L1 status. Among PD-L1 positive subjects, 53% subjects were randomized to avelumab plus BSC group ($r_{PD-L1+}=0.53$). Among the subjects not PD-L1 positive,  47% subjects were randomized to avelumab plus BSC group ($r_{not PD-L1+}=0.47$). Among all subjects in overall population, 51% subjects are in PD-L1 positive population ($\gamma=0.51$). One interim analysis was performed with 143 events in PD-L1+ subgroup and 324 events in overall population after the study is fully enrolled.

Several strategies of improving the rejection boundaries are calculated below.

### Equal Allocation: $\epsilon_{11} = \epsilon_{21}$, and $\epsilon_{12} = \epsilon_{22}$

```{r}
jv100a = corrBounds(sf=list(sfuA=gsDesign::sfLDOF, sfuB=gsDesign::sfLDOF),  eAandB = c(143, 219), eAnotB = c(0,0), eBnotA = c(181, 206), r=list(AandB = 189/358, AnotB=0, BnotA=(350-189)/(700-358)), rA=189/358, rB=350/700, gamma = 358/700, strat.ana="N",alpha=0.025, w=c(0.01/0.025, 0.015/0.025),epsA = c(NA,NA), epsB=c(NA,NA), method="Customized Allocation")

jv100a
```

###  Improve the overall population only: $\epsilon_{11} = \epsilon_{12} = 1$


```{r}
jv100b = corrBounds(sf=list(sfuA=gsDesign::sfLDOF, sfuB=gsDesign::sfLDOF),  eAandB = c(143, 219), eAnotB = c(0,0), eBnotA = c(181, 206), r=list(AandB = 189/358, AnotB=0, BnotA=(350-189)/(700-358)), rA=189/358, rB=350/700, gamma = 358/700, strat.ana="N",alpha=0.025, w=c(0.01/0.025, 0.015/0.025),epsA = c(1,1), epsB=c(NA,NA), method="Customized Allocation")

jv100b
```

### Improve the PD-L1+ only: $\epsilon_{21} = \epsilon_{22} = 1$

```{r}
jv100c = corrBounds(sf=list(sfuA=gsDesign::sfLDOF, sfuB=gsDesign::sfLDOF),  eAandB = c(143, 219), eAnotB = c(0,0), eBnotA = c(181, 206), r=list(AandB = 189/358, AnotB=0, BnotA=(350-189)/(700-358)), rA=189/358, rB=350/700, gamma = 358/700, strat.ana="N",alpha=0.025, w=c(0.01/0.025, 0.015/0.025),epsA = c(NA,NA), epsB=c(1,1), method="Customized Allocation")

jv100c
```

# Function `corrPower`

This function calculates the powers at specified analysis times based on the asymptotic distribution of the log-rank test statistics in overalapping populations under H1. For group sequential design, the power will be calculated for each analysis and overall study.

## Example 4. 

Consider a study with 1:1 randomization and the enrollment follows non-uniform enrollment distribution with weight 1.5 and enrollment period is 18 months, i.e., the cumulative enrollment at time $t$ is $\Lambda(t) = (\frac{t}{18})^{1.5}I_{t\le 18}+I_{t>18}$. Assume the control arm follows an exponential distribution with median 12 months. Assuming 3\% drop-off per 12 months of followup. There are two dual primary endpoints: a subgroup and overall population. Assume there are 250 subjects in the subgroup and 600 subjects in overall population. Three Analyses are planned at 24 mo, 36 mo, and 42 mo after first subject in. Assumed HR: 0.60 for the subgroup, and 0.80 for the complementary subgroup, so the HR for overall population is approximately 0.71.

```{r}
pow =  corrPower(T = c(24, 36), n = list(AandB = 350, AnotB=0, BnotA=240), 
        r = list(AandB=1/2, AnotB =0, BnotA = 1/2), 
        sf=list(sfuA=gsDesign::sfLDOF, sfuB=gsDesign::sfLDOF), 
        h0=list(AandB=function(t){log(2)/12}, AnotB=function(t){log(2)/12}, 
               BnotA=function(t){log(2)/12}), 
        S0=list(AandB=function(t){exp(-log(2)/12*t)}, AnotB=function(t){exp(-log(2)/12*t)},
               BnotA=function(t){exp(-log(2)/12*t)}),
        h1=list(AandB=function(t){log(2)/12*0.6},    AnotB=function(t){log(2)/12*0.6},
               BnotA=function(t){log(2)/12*0.80}), 
        S1=list(AandB=function(t){exp(-log(2)/12 * 0.6 * t)},
                AnotB=function(t){exp(-log(2)/12 * 0.6 * t)},
                BnotA=function(t){exp(-log(2)/12 * 0.80 * t)}),
        strat.ana=c("Y", "N"),
        alpha=0.025, w=c(1/3, 2/3), epsilon = list(epsA = c(NA,NA), epsB=c(1,1)),
        method=c("Balanced Allocation", "Customized Allocation"),      F.entry = function(t){(t/18)^1.5*as.numeric(t <= 18) + as.numeric(t > 18)}, 
           G.ltfu = function(t){1-exp(-0.03/12*t)}, variance="H1")

pow
```


# Function `corrTime`

This function calculates the correlation of two logrank test statistics on overlapping populations A and B over time calculated from first subject in. 

## Example 5

Consider the control arm has exponential distribution with median 12 months in all strata and 1:1 randomization stratified by PD-L1+ status. There are 300 subjects in PD-L1+ and 450 total subjects in overall population. Assume 3\% drop-off for every year's followup. Enrollment period is 18 months and weight 1.5. Define various distributions of the experimental arm, with the hazard functions and survival functions specified below.

```{r}
#################
# h(t) and S(t)
#################

h0 = function(t){log(2)/12}
S0 = function(t){exp(-log(2)/12 * t)}
h0.5 = function(t){log(2)/12*0.5}
h0.65 = function(t){log(2)/12*0.65}
h0.8 = function(t){log(2)/12*0.8}
S0.5 = function(t){exp(-log(2)/12 * 0.5 * t)}
S0.65 = function(t){exp(-log(2)/12 * 0.65 * t)}
S0.8 = function(t){exp(-log(2)/12 * 0.8 * t)}
```

The entry and drop-off distributions are defined herein. 

```{r}
#Entry distribution: enrollment period 18 mo, acceleration weight 1.5.
Fe = function(t){(t/18)^1.5*as.numeric(t <= 18) + as.numeric(t > 18)}

#Drop-off distribution: 3\% drop-off every year.
G = function(t){1-exp(-0.03/12*t)}

```

Plot correlation over time after enrollment complete

```{r}
t = seq(18, 100, 1) #Analysis time, must be greater than enrollment period 18.
omega = matrix(NA, nrow=6, ncol=length(t))

for (i in 1:length(t)){
  #(1) Homogeneous regardless of PD-L1 status: HR = 0.65
  omega[1,i]=corrTime(T = t[i], n = list(AandB = 300, AnotB=0, BnotA=450), 
      r = list(AandB=1/2, AnotB =0, BnotA = 1/2), rA=1/2, rB=1/2, 
      h0=list(AandB=h0, AnotB=h0, BnotA=h0), 
      S0=list(AandB=S0, AnotB=S0, BnotA=S0),
      h1=list(AandB=h0.65, AnotB=NULL, BnotA=h0.65), 
      S1=list(AandB=S0.65, AnotB=NULL, BnotA=S0.65),
      F.entry = Fe, G.ltfu = G, strat.ana="Y")$corr
      
  omega[2,i]=corrTime(T = t[i], n = list(AandB = 300, AnotB=0, BnotA=450), 
      r = list(AandB=1/2, AnotB =0, BnotA = 1/2), rA=1/2, rB=1/2, 
      h0=list(AandB=h0, AnotB=h0, BnotA=h0), 
      S0=list(AandB=S0, AnotB=S0, BnotA=S0),
      h1=list(AandB=h0.65, AnotB=NULL, BnotA=h0.65), 
      S1=list(AandB=S0.65, AnotB=NULL, BnotA=S0.65),
      F.entry = Fe, G.ltfu = G, strat.ana="N")$corr
      
  #(2) Stronger effect in PD-L1+: HR = 0.65; PD-L1-: HR = 0.85
  omega[3,i]=corrTime(T = t[i], n = list(AandB = 300, AnotB=0, BnotA=450), 
      r = list(AandB=1/2, AnotB =0, BnotA = 1/2), rA=1/2, rB=1/2,
      h0=list(AandB=h0, AnotB=h0, BnotA=h0), 
      S0=list(AandB=S0, AnotB=S0, BnotA=S0),
      h1=list(AandB=h0.65, AnotB=NULL, BnotA=h0.8), 
      S1=list(AandB=S0.65, AnotB=NULL, BnotA=S0.8),
      F.entry = Fe, G.ltfu = G, strat.ana="Y")$corr
      
  omega[4,i]=corrTime(T = t[i], n = list(AandB = 300, AnotB=0, BnotA=450), 
      r = list(AandB=1/2, AnotB =0, BnotA = 1/2), rA=1/2, rB=1/2,
      h0=list(AandB=h0, AnotB=h0, BnotA=h0), 
      S0=list(AandB=S0, AnotB=S0, BnotA=S0),
      h1=list(AandB=h0.65, AnotB=NULL, BnotA=h0.8), 
      S1=list(AandB=S0.65, AnotB=NULL, BnotA=S0.8),
      F.entry = Fe, G.ltfu = G, strat.ana="N")$corr
      
  #(3) Weaker effect in PD-L1+: HR = 0.85; PD-L1-: HR = 0.65
  omega[5,i]=corrTime(T = t[i], n = list(AandB = 300, AnotB=0, BnotA=450), 
      r = list(AandB=1/2, AnotB =0, BnotA = 1/2), rA=1/2, rB=1/2, 
      h0=list(AandB=h0, AnotB=h0, BnotA=h0), 
      S0=list(AandB=S0, AnotB=S0, BnotA=S0),
      h1=list(AandB=h0.65, AnotB=NULL, BnotA=h0.5), 
      S1=list(AandB=S0.65, AnotB=NULL, BnotA=S0.5),
      F.entry = Fe, G.ltfu = G, strat.ana="Y")$corr
      
  omega[6,i]=corrTime(T = t[i], n = list(AandB = 300, AnotB=0, BnotA=450), 
      r = list(AandB=1/2, AnotB =0, BnotA = 1/2), rA=1/2, rB=1/2,
      h0=list(AandB=h0, AnotB=h0, BnotA=h0), 
      S0=list(AandB=S0, AnotB=S0, BnotA=S0),
      h1=list(AandB=h0.65, AnotB=NULL, BnotA=h0.5), 
      S1=list(AandB=S0.65, AnotB=NULL, BnotA=S0.5),
      F.entry = Fe, G.ltfu = G, strat.ana="N")$corr
}

#Plot the correlations vs time
par(mar=c(6, 4.1, 4.1, 2.1))
plot(t, omega[1,], type="n", ylim=range(omega),
     ylab="Correlation", cex.lab=0.8, xlab="")
title(xlab="Analysis Time (months)", line=3.2, cex.lab=0.8)
lines(t, omega[1,], lty=1, col=1, lwd=1, type="b", pch=1, cex=0.8)
lines(t, omega[2,], lty=2, col=1, lwd=1, type="b", pch=3, cex=0.8)
lines(t, omega[3,], lty=3, col=1, lwd=1, type="b", pch=2, cex=0.8)
lines(t, omega[4,], lty=4, col=1, lwd=1, type="b", pch=2, cex=0.8)
lines(t, omega[5,], lty=5, col=1, lwd=1, type="b", pch=4, cex=0.8)
lines(t, omega[6,], lty=6, col=1, lwd=1, type="b", pch=4, cex=0.8)
legend(x="bottomleft", inset=c(0, -.35), 
       c("M+/- HR 0.65/0.65: S", "M+/- HR 0.65/0.65: U"), xpd = TRUE,
       col=rep(1,2), lty=1:2, bty="n", cex=0.6, pch=c(1, 3)) 
legend(x="bottom", inset=c(0, -.35), 
       c("M+/- HR 0.65/0.8: S","M+/- HR 0.65/0.8: U"), xpd = TRUE,
       col=rep(1,2), lty=3:4, bty="n", cex=0.6, pch=c(2, 2)) 

legend(x="bottomright", inset=c(0, -.35),  
       c("M+/- HR 0.65/0.5: S","M+/- HR 0.65/0.5: U"),xpd = TRUE,
       col=rep(1,2), lty=5:6, bty="n", cex=0.6, pch=c(4, 4))

```
